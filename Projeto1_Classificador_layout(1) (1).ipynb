{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Leonardo Fernandes Farah Elias\n",
    "\n",
    "Nome: Paulo Souza Chade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atenção:** Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e32c2f6aefcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0memoji\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "pd.options.display.max_rows = 13\n",
    "import math\n",
    "import random\n",
    "import re \n",
    "import sys\n",
    "import functools\n",
    "import operator\n",
    "import emoji\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = 'Iphone_CDados.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'Não encontrei o arquivo {filename} aqui no diretório {os.getcwd()}, será que você não baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-589e7ab4c892>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdados\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdados\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filename' is not defined"
     ]
    }
   ],
   "source": [
    "dados = pd.read_excel(filename)\n",
    "dados.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teste = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "teste.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "    Depois de algumas pesquisas, chegamos a conclusão que o trabalho seria melhor aproveitado, caso escolheriamos o Iphone como produto. Com o novo lançamento da Apple, houve uma maior repercussão na internet a respeito do celular que acabou não sendo atualizado pela marca. Dessa forma, concluimos que com um item muito presente no no dia a dia, seria uma boa oportunidade para conhecer melhor os dados. \n",
    "    Mesmo com a pandemia, o Iphone 11 foi o celular mais vendido no primeiro semestre de 2020. Portando, utilizamos o nosso algoritmo para classificar os comentários mais relevantes ou irrelevantes no twiteer. Consideramos relevantes, os comentários que sugeriam melhoras no produto (bateria, brilho, preço), críticas construtivas e também comparações feitas por usuários com outras marcas. Já os comentários irrelevantes, foram aqueles que não sugeriam nenhum conteúdo relacionado ao Iphone, como por exemplo: conversas paralelas e respostas feitas a usuários desconhecidos (retweet). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de limpeza muito simples que troca alguns sinais básicos por espaços.\n",
    "def cleanup(text):\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n",
    "\n",
    "# Função de limpeza muito simples que remove o arroba.\n",
    "def remove_arroba(lista):\n",
    "    arroba = \"@\"\n",
    "    for i in lista: \n",
    "        if arroba in i:\n",
    "            lista.remove(i)\n",
    "    return lista\n",
    "\n",
    "# Função de limpeza muito simples que remove as \\ e links.\n",
    "def remove_link(lista):\n",
    "    link = \"/\"\n",
    "    for i in lista: \n",
    "        if link in i:\n",
    "            lista.remove(i)\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dados' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-dc8e9427a2e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Filtros para Relevante e Irrelevante.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mRelevante\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdados\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Filtro\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mIrrelevante\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdados\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Filtro\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Criando data frame com filtro.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mRelevante\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdados\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRelevante\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dados' is not defined"
     ]
    }
   ],
   "source": [
    "# Filtros para Relevante e Irrelevante.\n",
    "Relevante = dados[\"Filtro\"].isin([\"1\"])\n",
    "Irrelevante = dados[\"Filtro\"].isin([\"0\"])\n",
    "# Criando data frame com filtro.\n",
    "Relevante = dados.loc[Relevante, :]\n",
    "Irrelevante = dados.loc[Irrelevante, :]\n",
    "# Variáveis que serão utilizadas na função para criar uma lista.\n",
    "Treino_Relevante = Relevante[\"Treinamento\"]        # Variável com palavras Relevantes.\n",
    "Treino_Irrelevante = Irrelevante[\"Treinamento\"]    # Variável com palavras Irrelevantes.\n",
    "\n",
    "# Número de frases classificadas como Relevantes ou Irrelevantes (.count).\n",
    "total_frases_relevantes = Relevante.count()[0]\n",
    "total_frases_irrelevantes = Irrelevante.count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Treino_Relevante' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-804f109907d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Transformando em lista por meio da função make_list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mtodas_palavras_relevantes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTreino_Relevante\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mtodas_palavras_irrelevantes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTreino_Irrelevante\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Treino_Relevante' is not defined"
     ]
    }
   ],
   "source": [
    "# Função criada para transformar a coluna no data frame com palavras Relevantes e Irrelevantes em lista.\n",
    "def make_list(Treino_Relevante):\n",
    "    treinamento_relevante = []\n",
    "    # Fazendo a lista.\n",
    "    for i in Treino_Relevante:\n",
    "        treinamento_relevante.append(i)\n",
    "\n",
    "    coma = \"'\"\n",
    "    # Transformar em texto.\n",
    "    treinamento_relevante = coma.join(treinamento_relevante)\n",
    "    # Função que limpa (já criada em cima).\n",
    "    limpa = cleanup(treinamento_relevante)\n",
    "    # Transforma em letras minúsculas.\n",
    "    minusculo = limpa.lower()\n",
    "    palavras_relevantes = minusculo.split()\n",
    "    \n",
    "    # Removendo/separando emoji.\n",
    "    lista_nova = []\n",
    "    for i in palavras_relevantes: \n",
    "        em_split_emoji = emoji.get_emoji_regexp().split(i)\n",
    "        em_split_whitespace = [o.split() for o in em_split_emoji]\n",
    "        em_split = functools.reduce(operator.concat, em_split_whitespace)\n",
    "        lista_nova.append(em_split)\n",
    "    \n",
    "    lista_emoji = []\n",
    "    for w in lista_nova:\n",
    "        for j in w:\n",
    "            lista_emoji.append(j)\n",
    "    \n",
    "    # Usando funções que ja foram criadas.\n",
    "    lista = remove_arroba(lista_emoji)\n",
    "    lista = remove_link(lista)\n",
    "    return lista\n",
    "\n",
    "# Transformando em lista por meio da função make_list.\n",
    "todas_palavras_relevantes = make_list(Treino_Relevante)\n",
    "todas_palavras_irrelevantes = make_list(Treino_Irrelevante) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdSeries.\n",
    "serie_relevante = pd.Series(todas_palavras_relevantes)\n",
    "serie_irrelevante = pd.Series(todas_palavras_irrelevantes)\n",
    "\n",
    "# Criando tabelas de frequencia relativas.\n",
    "tabela_relevantes = serie_relevante.value_counts()\n",
    "tabela_irrelevantes = serie_irrelevante.value_counts()\n",
    "Nr = sum(tabela_relevantes)\n",
    "Ni = sum(tabela_irrelevantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa(tweet):\n",
    "    pri = cleanup(tweet)\n",
    "    return pri\n",
    "# Criaremos duas funções para ambas as probabilidades. \n",
    "# Função da probabilidade de ser frase dado que ela é Relevante P(frase/relevante).\n",
    "def P_tweet_dado_relevante(lista): \n",
    "    prob_tweet_dado_relevante = 0\n",
    "    alpha = 1\n",
    "    V = 100000\n",
    "    prob_tweets = []\n",
    "    for tweet in lista:\n",
    "        prob_tweet_dado_relevante = 0\n",
    "        tweet_minusculo = tweet.lower()\n",
    "        tweet_limpo = limpa(tweet_minusculo) \n",
    "        lista_limpo = tweet_limpo.split()\n",
    "        \n",
    "        # Removendo/separando emoji.\n",
    "        lista_nova = []\n",
    "        for i in lista_limpo: \n",
    "            em_split_emoji = emoji.get_emoji_regexp().split(i)\n",
    "            em_split_whitespace = [o.split() for o in em_split_emoji]\n",
    "            em_split = functools.reduce(operator.concat, em_split_whitespace)\n",
    "            lista_nova.append(em_split)\n",
    "        \n",
    "        # Organizando os emojis na lista.\n",
    "        lista_emoji = []\n",
    "        for w in lista_nova:\n",
    "            for j in w:\n",
    "                lista_emoji.append(j)\n",
    "        \n",
    "        lista_limpo = remove_arroba(lista_emoji)\n",
    "        lista_limpo = remove_link(lista_limpo)\n",
    "        \n",
    "        # Calculando a probabilidade.\n",
    "        for palavra in lista_limpo:\n",
    "            if palavra in tabela_relevantes:\n",
    "                prob_palavra_dado_relevante = (tabela_relevantes[palavra] + alpha)/ (Nr+(V * alpha))\n",
    "            else:\n",
    "                prob_palavra_dado_relevante = alpha/(Nr + (alpha * V))\n",
    "            \n",
    "            # Ao invés de utilizarmos um produtório fizemos um somatório com log.\n",
    "            prob_tweet_dado_relevante += math.log(prob_palavra_dado_relevante)\n",
    "        \n",
    "        prob_tweets.append(prob_tweet_dado_relevante)\n",
    "        \n",
    "    return prob_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função da probabilidade de ser frase dado que ela é Irrelevante P(frase/irrelevante).\n",
    "def P_tweet_dado_irrelevante(lista):\n",
    "    prob_tweet_dado_irrelevante = 0\n",
    "    alpha = 1\n",
    "    V = 100000\n",
    "    prob_tweets = []\n",
    "    for tweet in lista:\n",
    "        prob_tweet_dado_irrelevante = 0\n",
    "        tweet_minusculo = tweet.lower()\n",
    "        tweet_limpo = limpa(tweet_minusculo)\n",
    "        lista_limpo = tweet_limpo.split()\n",
    "        \n",
    "        # Removendo/separando emoji.\n",
    "        lista_nova = []\n",
    "        for i in lista_limpo: \n",
    "            em_split_emoji = emoji.get_emoji_regexp().split(i)\n",
    "            em_split_whitespace = [o.split() for o in em_split_emoji]\n",
    "            em_split = functools.reduce(operator.concat, em_split_whitespace)\n",
    "            lista_nova.append(em_split)\n",
    "        \n",
    "        # Organizando os emojis na lista.\n",
    "        lista_emoji = []\n",
    "        for w in lista_nova:\n",
    "            for j in w:\n",
    "                lista_emoji.append(j)\n",
    "        \n",
    "        lista_limpo = remove_arroba(lista_emoji)\n",
    "        lista_limpo = remove_link(lista_limpo)\n",
    "             \n",
    "        # Calculando a probabilidade.\n",
    "        for palavra in lista_limpo:\n",
    "            if palavra in tabela_irrelevantes:\n",
    "                prob_palavra_dado_irrelevante = (tabela_irrelevantes[palavra] + alpha)/ (Ni+(V * alpha))\n",
    "            else:\n",
    "                prob_palavra_dado_irrelevante = alpha/(Ni + (alpha * V))\n",
    "                \n",
    "            # Ao invés de utilizarmos um produtório fizemos um somatório com log.\n",
    "            prob_tweet_dado_irrelevante += math.log(prob_palavra_dado_irrelevante)\n",
    "        \n",
    "        prob_tweets.append(prob_tweet_dado_irrelevante)\n",
    "        \n",
    "    return prob_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando as probabilidades.\n",
    "# Probabilidade de ser Relevante.\n",
    "P_R = total_frases_relevantes/(total_frases_relevantes+total_frases_irrelevantes)\n",
    "# Probabilidade de ser Irrelevante.\n",
    "P_I = 1 - P_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_relevante = teste[\"Filtro\"].isin([\"1\"])\n",
    "teste_irrelevante = teste[\"Filtro\"].isin([\"0\"])\n",
    "Teste_Relevante = teste.loc[teste_relevante, :]\n",
    "Teste_Irrelevante = teste.loc[teste_irrelevante, :]\n",
    "\n",
    "def lista_treino(data_frame):    \n",
    "    lista_teste = []\n",
    "    for i in data_frame[\"Teste\"]:\n",
    "        lista_teste.append(i)\n",
    "\n",
    "    return lista_teste\n",
    "\n",
    "lista_teste = lista_treino(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista com valores negativos.\n",
    "Prob_tweet_dado_relevante = P_tweet_dado_relevante(lista_teste)\n",
    "Prob_tweet_dado_irrelevante = P_tweet_dado_irrelevante(lista_teste)\n",
    "\n",
    "Prob_relevante_dado_tweet = [i + math.log(P_R) for i in Prob_tweet_dado_relevante]\n",
    "Prob_irrelevante_dado_tweet = [i + math.log(P_I) for i in Prob_tweet_dado_irrelevante]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For que transforma a lista com valores de 0 e 1 (Irrelevante e Relevante, respectivamente).\n",
    "valor_maior = []\n",
    "for i in range(len(Prob_relevante_dado_tweet)):\n",
    "    if Prob_relevante_dado_tweet[i] > Prob_irrelevante_dado_tweet[i]:\n",
    "        valor_maior.append(1)\n",
    "    else:\n",
    "        valor_maior.append(0)\n",
    "\n",
    "#sum(valor_maior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Filtro</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>90.24</td>\n",
       "      <td>9.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>78.79</td>\n",
       "      <td>21.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0      1\n",
       "Filtro                 \n",
       "0          90.24   9.76\n",
       "1          78.79  21.21"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabela cruzada para ver indíces de acertos, qualidade do nosso algoritmo.\n",
    "teste[\"Predicted\"] = valor_maior\n",
    "x = (100 * pd.crosstab(teste.Filtro, teste.Predicted, normalize = \"index\")).round(decimals=2)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse projeto foi implementado um classificador Naive Bayes com o intuito de classificar tweets de um produto, neste caso o Iphone, em diferentes categorias de relevância. Após classifica-los manualmente em relevante(1) e irrelevante(0), foi necessário separar os dados em duas categorias: Treinamento e Teste. Isso é crucial pois, caso a mesma base de dados seja usada para treinar e testar o algoritimo, o resultado sera totalmente enviesado, o algoritimo terá um rendimento muito alto, porém não representativo de sua real eficiência, seria a mesma coisa que um professor dar em uma prova, o mesmo exercício dado em aula, o aluno acertaria porque ele sabe o resultado, e as vezes ele relamente não sabe fazer.\n",
    "\n",
    "Após dividir os dados entre treinamento (3/4 dos dados aproximadamente) e teste (1/4 dos dados), o classificador foi treinado e testado, contudo a eficacia do mesmo não foi alta, ESCREVER PORCENTAGENS. \n",
    "\n",
    "Contudo, essa baixa eficiência não foi surpreendente, como o próprio nome do classificador diz ele é ingenuo, assim ele estabelece que em uma frase todas as palavras são independentes, o que certamente não é verdade, frases com dupla negação e/ou sarcásticas, não são analisadas de maneira correta. além de tudo é um classificador muito simples.\n",
    "\n",
    "Mesmo com essas características melhorias poderiam ser feitas para aumentar os acertos do classificador, uma das práticas muito utilizadas pelos programadores de Machine Learning é o counter-validation test, que é usado para escolher parâmetros presentes nas equações, neste caso o alpha do classificador. Está pratica consiste em comparar diferentes valores para os parâmetros escolhidos, com a eficiência final, por fim deve-se escolher os paramentros que trazem a maior eficácia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
